<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>AI on Flyfan Blog</title>
        <link>https://downeyflyfan.com/categories/ai/</link>
        <description>Recent content in AI on Flyfan Blog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Sat, 16 Mar 2024 11:54:05 +0800</lastBuildDate><atom:link href="https://downeyflyfan.com/categories/ai/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>1. 常用库</title>
        <link>https://downeyflyfan.com/p/1.-%E5%B8%B8%E7%94%A8%E5%BA%93/</link>
        <pubDate>Sat, 16 Mar 2024 11:54:05 +0800</pubDate>
        
        <guid>https://downeyflyfan.com/p/1.-%E5%B8%B8%E7%94%A8%E5%BA%93/</guid>
        <description>&lt;h1 id=&#34;常用库&#34;&gt;常用库&lt;/h1&gt;
&lt;h2 id=&#34;pytorch&#34;&gt;Pytorch&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;函数&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;含义&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;常见用法示例&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;torch.randn&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;随机生成Tensor&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;torch.randn(1, 3, 256, 256) # NxCxHxW&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;torch.nn.Conv2d&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;卷积&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;torch.nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=1)&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;torch.nn.ConvTranspose2d&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;逆卷积, $Output = \Big[ \dfrac{ H + 2P - K }{ S } + 1 \Big] \times \Big[ \dfrac{ W + 2P - K }{ S } + 1\Big]$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;self.deconv = nn.ConvTranspose2d(in_channels=spectral_num, out_channels=spectral_num, kernel_size=8, stride=4,padding=2, bias=True)&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;torch.nn.Sequential&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;创建按顺序执行的神经网络&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;self.backbone = nn.Sequential(self.res1,self.res2,self.res3,self.res4)&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;torchsummary.summary&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;输出神经网络的摘要信息&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;summary(model, input_size=[(8, 16, 16), (1, 64, 64)], batch_size=1)&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;SummaryWriter&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;将数据写入TensorBoard日志文件&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;writer = SummaryWriter(&#39;./train_logs/50&#39;)&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;torch.cat&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;拼接变量，拼接纬度&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;input = torch.cat([output_deconv, y], 1)  # Bsx9x64x64&lt;/code&gt;, 1表示从第二个纬度(此处为C)开始拼接&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;torch.utils.data.DataLoader&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;数据加载, &lt;code&gt;num_workers&lt;/code&gt;表示线程数，为0表示在主线程中加载, &lt;code&gt;drop_last(bool)&lt;/code&gt; 设为True会丢弃最后一个batch的剩余样本,确保每个batch都有batch_size个样本。&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;training_data_loader = DataLoader(dataset=train_set, num_workers=0, batch_size=batch_size, shuffle=True, pin_memory=True, drop_last=True)&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;cv2--h5py&#34;&gt;CV2 &amp;amp; h5py&lt;/h2&gt;
&lt;h2 id=&#34;cv2-函数&#34;&gt;CV2 函数&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;函数&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;含义&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;常见用法&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;cv2.boxFilter&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;方框滤波&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;cv2.boxFilter(data[i, :, :], -1, (5, 5))&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;h5py&#34;&gt;h5py&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;HDF5 是一种数据存储格式和库，用于有效地组织、存储和管理大量的科学数据。HDF5 文件可以包含多个数据集（dataset）和组（group），以层次结构的方式组织数据。每个数据集可以存储多维数组、表格数据、图像、文本等各种类型的数据。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;常用简写&#34;&gt;常用简写&lt;/h1&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Category&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Concept&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;Resblock&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;strong&gt;Residual Block&lt;/strong&gt;, 残差块&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
        </item>
        
    </channel>
</rss>
